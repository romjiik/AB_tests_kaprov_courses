{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "from scipy.stats import norm, ttest_ind\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 1\n",
    "Сколько несовместных независимых экспериментов можно запустить одновременно, если за время эксперимента собираем 10000 наблюдений?\n",
    "\n",
    "Если решаем запустить 10 экспериментов, то на каждый эксперимент можно выделить по 1000 наблюдений, размер групп будет равен 500.\n",
    "\n",
    "Параметры экспериментов:\n",
    "\n",
    "- проверяем гипотезу о равенстве средних;\n",
    "- уровень значимости — 0.05;\n",
    "- допустимая вероятность ошибки II рода — 0.1;\n",
    "- ожидаемый эффект — увеличение значений на 3%;\n",
    "- способ добавления эффекта в синтетических А/Б экспериментах — умножение на константу.\n",
    "\n",
    "Будем считать, что распределение измеряемых величин является нормальным распределением со средним 100 и стандартным отклонением 10.\n",
    "\n",
    "В качестве ответа введите максимально возможное количество экспериментов, которое можно запустить с указанными выше параметрами.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Надо посчитать количество экспериментов, чтобы в каждом были эффекты сверху. То есть надо посчитать количество наблюдений для одного эксперимента с учетом поправки на множественное тестирование и разделить 10к на это число"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample_size_abs(epsilon, std, alpha=0.05, beta=0.2):\n",
    "    t_alpha = norm.ppf(1 - alpha / 2, loc=0, scale=1)\n",
    "    t_beta = norm.ppf(1 - beta, loc=0, scale=1)\n",
    "    z_scores_sum_squared = (t_alpha + t_beta) ** 2\n",
    "    sample_size = int(\n",
    "        np.ceil(\n",
    "            z_scores_sum_squared * (2 * std ** 2) / (epsilon ** 2)\n",
    "        )\n",
    "    )\n",
    "    return sample_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample_size_arb(mu, std, eff=1.01, alpha=0.05, beta=0.2):\n",
    "    epsilon = (eff - 1) * mu\n",
    "\n",
    "    return get_sample_size_abs(epsilon, std=std, alpha=alpha, beta=beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21.367521367521366"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_observation = 10000\n",
    "alpha = 0.05\n",
    "beta = 0.1\n",
    "effect = 1.03\n",
    "mean = 100\n",
    "std = 10\n",
    "\n",
    "total_observation / (get_sample_size_arb(mean, std, effect, alpha=alpha, beta=beta) * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_size = 233\n",
      "count_exp = 21.5\n",
      "count_exp = 20\n",
      "sample_size = 250\n",
      "оценка вероятности ошибки I рода = 0.0546\n",
      "  доверительный интервал = [0.0501, 0.0591]\n",
      "оценка вероятности ошибки II рода = 0.0945\n",
      "  доверительный интервал = [0.0888, 0.1002]\n",
      "count_exp = 21\n",
      "sample_size = 238\n",
      "оценка вероятности ошибки I рода = 0.0504\n",
      "  доверительный интервал = [0.0461, 0.0547]\n",
      "оценка вероятности ошибки II рода = 0.1078\n",
      "  доверительный интервал = [0.1017, 0.1139]\n",
      "count_exp = 22\n",
      "sample_size = 227\n",
      "оценка вероятности ошибки I рода = 0.0477\n",
      "  доверительный интервал = [0.0435, 0.0519]\n",
      "оценка вероятности ошибки II рода = 0.1211\n",
      "  доверительный интервал = [0.1147, 0.1275]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# параметры эксперимента\n",
    "total_size = 10000\n",
    "mean_ = 100\n",
    "std_ = 10\n",
    "effect = 0.03\n",
    "alpha = 0.05\n",
    "beta = 0.1\n",
    "\n",
    "\n",
    "def estimate_sample_size(effect, std, alpha, beta):\n",
    "    \"\"\"Оценка необходимого размер групп.\"\"\"\n",
    "    t_alpha = stats.norm.ppf(1 - alpha / 2, loc=0, scale=1)\n",
    "    t_beta = stats.norm.ppf(1 - beta, loc=0, scale=1)\n",
    "    var = 2 * std ** 2\n",
    "    sample_size = int((t_alpha + t_beta) ** 2 * var / (effect ** 2))\n",
    "    return sample_size\n",
    "\n",
    "\n",
    "# оценим необходимый размер групп\n",
    "sample_size = estimate_sample_size(effect * 100, 10, alpha, beta)\n",
    "print(f'sample_size = {sample_size}')\n",
    "# вычислим количество экспериментов\n",
    "count_exp = total_size / (sample_size * 2)\n",
    "print(f'count_exp = {count_exp:0.1f}')\n",
    "\n",
    "\n",
    "def estimate_ci_bernoulli(p, n, alpha=0.05):\n",
    "    \"\"\"Доверительный интервал для Бернуллиевской случайной величины.\"\"\"\n",
    "    t = stats.norm.ppf(1 - alpha / 2, loc=0, scale=1)\n",
    "    std_n = np.sqrt(p * (1 - p) / n)\n",
    "    return p - t * std_n, p + t * std_n\n",
    "\n",
    "# Проверим, что при 21 эксперимента ошибки контролируются на заданных уровнях, а при 22 экспериментах нет.\n",
    "\n",
    "for count_exp in [20, 21, 22]:\n",
    "    errors_aa = []\n",
    "    errors_ab = []\n",
    "    sample_size = int(total_size / (int(count_exp) * 2))\n",
    "    for _ in range(10000):\n",
    "        a, b = np.random.normal(mean_, std_, (2, sample_size,))\n",
    "        b_effect = b * (1 + effect)\n",
    "        errors_aa.append(stats.ttest_ind(a, b).pvalue < alpha)\n",
    "        errors_ab.append(stats.ttest_ind(a, b_effect).pvalue >= alpha)\n",
    "\n",
    "    estimated_first_type_error = np.mean(errors_aa)\n",
    "    estimated_second_type_error = np.mean(errors_ab)\n",
    "    ci_first = estimate_ci_bernoulli(estimated_first_type_error, len(errors_aa))\n",
    "    ci_second = estimate_ci_bernoulli(estimated_second_type_error, len(errors_ab))\n",
    "    print(f'count_exp = {count_exp}')\n",
    "    print(f'sample_size = {sample_size}')\n",
    "    print(f'оценка вероятности ошибки I рода = {estimated_first_type_error:0.4f}')\n",
    "    print(f'  доверительный интервал = [{ci_first[0]:0.4f}, {ci_first[1]:0.4f}]')\n",
    "    print(f'оценка вероятности ошибки II рода = {estimated_second_type_error:0.4f}')\n",
    "    print(f'  доверительный интервал = [{ci_second[0]:0.4f}, {ci_second[1]:0.4f}]')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 2\n",
    "\n",
    "Задача похожа на предыдущую, только теперь решение принимается не независимо для каждого эксперимента.\n",
    "Например, у нас есть 5 текстов для маркетинговой рассылки, хотим проверить, какой эффективнее работает и работает ли вообще.\n",
    "\n",
    "Алгоритм будет следующий:\n",
    "\n",
    "1. Формируем непересекающиеся контрольные и экспериментальные группы для каждого из 5 вариантов.\n",
    "2. Проводим параллельно 5 экспериментов.\n",
    "3. С помощью метода Холма определяем, в каких экспериментах были статистически значимые отличия.\n",
    "4. Если значимых отличий не обнаружено, то говорим, что эффекта нет, все варианты отклоняем.\n",
    "5. Если значимые отличия обнаружены, то из вариантов со значимым эффектом выбираем вариант с наименьшим значением p-value, будем использовать его.\n",
    "\n",
    "Будем считать, что совершена ошибка I рода, если найдены значимые отличия, когда на самом деле их не было ни в одном из вариантов.\n",
    "\n",
    "Будем считать, что совершена ошибка II рода, если:\n",
    "- либо не найдено значимых отличий, когда на самом деле они были;\n",
    "- либо выбранный для дальнейшего использования вариант на самом деле был без эффекта, при этом были варианты с эффектом.\n",
    "\n",
    "Параметры экспериментов:\n",
    "\n",
    "- проверяем гипотезу о равенстве средних;\n",
    "- уровень значимости — 0.05;\n",
    "- допустимая вероятность ошибки II рода — 0.1;\n",
    "- ожидаемый эффект — увеличение значений на 3%;\n",
    "- способ добавления эффекта в синтетических А/Б экспериментах — умножение на константу.\n",
    "\n",
    "Замечание: при оценке вероятности ошибки II рода нужно рассматривать худший сценарий, когда эффект есть только в одном из экспериментов. Чем в большем количестве экспериментов будет эффект, тем меньше будет вероятность ошибки II рода.\n",
    "\n",
    "Будем считать, что распределение измеряемых величин является нормальным распределением со средним 100 и стандартным отклонением 10.\n",
    "\n",
    "В качестве ответа введите максимально возможное количество экспериментов, которое можно запустить с указанными выше параметрами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count_exp = 12\n",
      "sample_size = 416\n",
      "оценка вероятности ошибки I рода = 0.0491\n",
      "  доверительный интервал = [0.0449, 0.0533]\n",
      "оценка вероятности ошибки II рода = 0.0870\n",
      "  доверительный интервал = [0.0815, 0.0925]\n",
      "count_exp = 13\n",
      "sample_size = 384\n",
      "оценка вероятности ошибки I рода = 0.0489\n",
      "  доверительный интервал = [0.0447, 0.0531]\n",
      "оценка вероятности ошибки II рода = 0.1252\n",
      "  доверительный интервал = [0.1187, 0.1317]\n"
     ]
    }
   ],
   "source": [
    "def method_holm(pvalues, alpha=0.05):\n",
    "    \"\"\"Применяет метод Холма для проверки значимости изменений.\n",
    "    \n",
    "    pvalues - List[float] - список pvalue.\n",
    "    alpha - float, уровень значимости.\n",
    "    return - np.array, массив из нулей и единиц, 0 - эффекта нет, 1 - эффект есть.\n",
    "    \"\"\"\n",
    "    m = len(pvalues)\n",
    "    array_alpha = np.arange(m, 0, -1)\n",
    "    array_alpha = alpha / array_alpha\n",
    "    sorted_pvalue_indexes = np.argsort(pvalues)\n",
    "    res = np.zeros(m)\n",
    "    for idx, pvalue_index in enumerate(sorted_pvalue_indexes):\n",
    "        pvalue = pvalues[pvalue_index]\n",
    "        alpha_ = array_alpha[idx]\n",
    "        if pvalue < alpha_:\n",
    "            res[pvalue_index] = 1\n",
    "        else:\n",
    "            break\n",
    "    res = res.astype(int)\n",
    "    return res\n",
    "\n",
    "# Проверим, что при 12 эксперимента ошибки контролируются на заданных уровнях, а при 13 экспериментах нет.\n",
    "\n",
    "for count_exp in [12, 13]:\n",
    "    errors_aa = []\n",
    "    errors_ab = []\n",
    "    sample_size = int(total_size / (int(count_exp) * 2))\n",
    "    for _ in (range(10000)):\n",
    "        list_ab_values = [\n",
    "            np.random.normal(mean_, std_, (2, sample_size))\n",
    "            for _ in range(count_exp)\n",
    "        ]\n",
    "        # синтетический А/А тест\n",
    "        pvalues = [stats.ttest_ind(a, b).pvalue for a, b in list_ab_values]\n",
    "        aa_with_effect = method_holm(pvalues, alpha)\n",
    "        errors_aa.append(np.sum(aa_with_effect) > 0)\n",
    "\n",
    "        # Синтетический А/Б тест.\n",
    "        # Достаточно проверить случай, когда эффект есть лишь в одном из экспериментов,\n",
    "        # так как при наличии эффектов в большем кол-ве экспериментов ошибок II рода станет меньше.\n",
    "        # Добавим эффект в первый эксперимент (не важно в какой добавлять, так как данные случайные)\n",
    "        list_ab_values[0][1] *= 1 + effect\n",
    "        pvalues = [stats.ttest_ind(a, b).pvalue for a, b in list_ab_values]\n",
    "        ab_with_effect = method_holm(pvalues, alpha)\n",
    "        if np.sum(ab_with_effect) == 0:\n",
    "            # если эффектов не найдено, то это ошибка\n",
    "            errors_ab.append(True)\n",
    "        else:\n",
    "            # если эффектов найден где его нет, то это ошибка\n",
    "            errors_ab.append(np.min(pvalues) != pvalues[0])\n",
    "\n",
    "    estimated_first_type_error = np.mean(errors_aa)\n",
    "    estimated_second_type_error = np.mean(errors_ab)\n",
    "    ci_first = estimate_ci_bernoulli(estimated_first_type_error, len(errors_aa))\n",
    "    ci_second = estimate_ci_bernoulli(estimated_second_type_error, len(errors_ab))\n",
    "    print(f'count_exp = {count_exp}')\n",
    "    print(f'sample_size = {sample_size}')\n",
    "    print(f'оценка вероятности ошибки I рода = {estimated_first_type_error:0.4f}')\n",
    "    print(f'  доверительный интервал = [{ci_first[0]:0.4f}, {ci_first[1]:0.4f}]')\n",
    "    print(f'оценка вероятности ошибки II рода = {estimated_second_type_error:0.4f}')\n",
    "    print(f'  доверительный интервал = [{ci_second[0]:0.4f}, {ci_second[1]:0.4f}]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1, 2, 3}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(sum([[1,2], [1,2], [1,3], [1,3]], []))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
